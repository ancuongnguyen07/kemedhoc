include "../../../arch/ppc64le/Vale.PPC64LE.InsBasic.vaf"
include "../../../arch/ppc64le/Vale.PPC64LE.InsVector.vaf"
include "Vale.AES.PPC64LE.PolyOps.vaf"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:fstar}{:open} "Vale.Arch.Types"
include{:fstar}{:open} "Vale.Arch.TypesNative"
include{:fstar}{:open} "Vale.Math.Poly2_s"
include{:fstar}{:open} "Vale.Math.Poly2"
include{:fstar}{:open} "Vale.Math.Poly2.Bits_s"
include{:fstar}{:open} "Vale.Math.Poly2.Bits"
include{:fstar}{:open} "Vale.Math.Poly2.Words"
include{:fstar}{:open} "Vale.Math.Poly2.Lemmas"
include{:fstar}{:open} "Vale.AES.GF128_s"
include{:fstar}{:open} "Vale.AES.GF128"
include{:fstar}{:open} "Vale.PPC64LE.Machine_s"
include{:fstar}{:open} "Vale.PPC64LE.State"
include{:fstar}{:open} "Vale.PPC64LE.Decls"
include{:fstar}{:open} "Vale.PPC64LE.QuickCode"
include{:fstar}{:open} "Vale.PPC64LE.QuickCodes"
include{:fstar}{:open} "Vale.AES.Types_helpers"
include{:fstar}{:open} "Vale.AES.GHash_BE"

module Vale.AES.PPC64LE.GF128_Mul

#verbatim{:interface}{:implementation}
open Vale.Def.Types_s
open Vale.Arch.Types
open Vale.Arch.TypesNative
open Vale.Math.Poly2_s
open Vale.Math.Poly2
open Vale.Math.Poly2.Bits_s
open Vale.Math.Poly2.Bits
open Vale.Math.Poly2.Lemmas
open Vale.AES.GF128_s
open Vale.AES.GF128
open Vale.PPC64LE.Machine_s
open Vale.PPC64LE.State
open Vale.PPC64LE.Decls
open Vale.PPC64LE.InsBasic
open Vale.PPC64LE.InsMem
open Vale.PPC64LE.InsVector
open Vale.PPC64LE.QuickCode
open Vale.PPC64LE.QuickCodes
open Vale.AES.PPC64LE.PolyOps
open Vale.AES.Types_helpers
open Vale.AES.GHash_BE
#endverbatim

procedure ShiftLeft128_1(ghost a:poly)
    {:public}
    {:quick}
    modifies
        v1; v2;
    requires
        degree(a) < 128;
        v1 == to_quad32(a);
    ensures
        v1 == to_quad32(shift(a, 1));
{
    Vspltisb(v2, 1);
    Vsl(v1, v1, v2);

    lemma_shift_left_1(a);
}

procedure ShiftLeft2_128_1(ghost lo:poly, ghost hi:poly)
    {:quick}
    modifies
        r10;
        v0; v1; v2; v3;
    requires
        degree(hi) < 127;
        degree(lo) <= 127;
        v1 == to_quad32(lo);
        v2 == to_quad32(hi);
    ensures
        let n := monomial(128);
        let a := add(mul(hi, n), lo);
        let b := shift(a, 1);
        v1 == to_quad32(mod(b, n));
        v2 == to_quad32(div(b, n));
{
    Vspltisw(v0, 0);
    LoadImm64(r10, 31);
    Mtvsrws(v3, r10);
    Vsrw(v3, v1, v3);
    Vsldoi(v3, v0, v3, 4);
    Vspltisb(v0, 1);
    Vsl(v1, v1, v0);
    Vsl(v2, v2, v0);
    Vxor(v2, v2, v3);

    let l := old(four_map(fun (i:nat32) ishl32(i, 1), v2));
    let r := old(four_map(fun (i:nat32) ishr32(i, 31), v2));
    lemma_quad32_xor_commutes(Mkfour(0, r.lo0, r.lo1, r.hi2), v3);
    lemma_quad32_xor_associates(l, Mkfour(0, r.lo0, r.lo1, r.hi2), v3);

    lemma_shift_2_left_1(lo, hi);
}

procedure ClmulRev64High(ghost a:poly, ghost b:poly)
    {:quick}
    reads
    modifies
        v1; v2;
    requires
        degree(a) <= 63;
        degree(b) <= 63;
        reverse(a, 63) == of_double32(quad32_double_hi(v1));
        reverse(b, 63) == of_double32(quad32_double_hi(v2));
        of_double32(quad32_double_lo(v1)) == zero \/
        of_double32(quad32_double_lo(v2)) == zero;
    ensures
        v1 == to_quad32(reverse(mul(a, b), 127));
{
    lemma_quad32_double(of_quad32(v1));
    lemma_quad32_double(of_quad32(v2));
    lemma_mask_is_mod(of_quad32(v1), 64);
    lemma_mask_is_mod(of_quad32(v2), 64);
    lemma_shift_is_div(of_quad32(v1), 64);
    lemma_shift_is_div(of_quad32(v2), 64);
    VPolyMulHigh(v1, v1, v2);
    ShiftLeft128_1(mul(reverse(a, 63), reverse(b, 63)));

    lemma_mul_reverse_shift_1(a, b, 63);
}

procedure High64ToLow(out dst:vec_opr, in src:vec_opr, ghost a:poly)
    {:public}
    {:quick exportOnly}
    reads
        v0;
    requires
        v0 == Mkfour(0, 0, 0, 0);
        degree(a) <= 127;
        src == to_quad32(a);
    ensures
        dst == to_quad32(div(a, monomial(64)));
{
    Vsldoi(dst, v0, src, 8); // (hi) 0 0 3 2 (lo)
    lemma_quad32_double_shift(a);
}

procedure Low64ToHigh(out dst:vec_opr, in src:vec_opr, ghost a:poly)
    {:public}
    {:quick expoOnly}
    reads
        v0;
    requires
        v0 == Mkfour(0, 0, 0, 0);
        degree(a) <= 127;
        src == to_quad32(a);
    ensures
        dst == to_quad32(mul(mod(a, monomial(64)), monomial(64)));
{
    Vsldoi(dst, src, v0, 8); // (hi) 1 0 3 3 (lo)
    lemma_quad32_double_shift(a);
}

procedure AddPoly(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr, ghost a:poly, ghost b:poly)
    {:quick exportOnly}
    requires
        degree(a) <= 127;
        degree(b) <= 127;
        src1 == to_quad32(a);
        src2 == to_quad32(b);
    ensures
        dst == to_quad32(add(a, b));
{
    Vxor(dst, src1, src2);
    lemma_add128(a, b);
}

procedure Clmul128(ghost ab:poly, ghost cd:poly) returns(ghost lo:poly, ghost hi:poly)
    {:quick}
    modifies
        v0; v1; v2; v3; v4; v5;
    requires
        degree(ab) <= 127;
        degree(cd) <= 127;
        v1 == to_quad32(ab);
        v2 == to_quad32(cd);
    ensures
        degree(lo) <= 127;
        degree(hi) < 127;
        mul(ab, cd) == add(shift(hi, 128), lo);
        v1 == to_quad32(lo);
        v2 == to_quad32(hi);
{
    let n := monomial(64);
    let a := div(ab, n);
    let b := mod(ab, n);
    let c := div(cd, n);
    let d := mod(cd, n);
    let ac := mul(a, c);
    let ad := mul(a, d);
    let bc := mul(b, c);
    let bd := mul(b, d);
    let ab_sw := swap(ab, 64);
    let ab_hi := mod(ab, n);
    let ab_lo := mul(div(ab, n), n);
    lemma_quad32_double(ab);
    lemma_quad32_double(cd);

    Vspltisw(v0, 0);
    VSwap(v3, v1);
    lemma_of_to_quad32(ab);
    lemma_quad32_double_swap(ab);
    lemma_quad32_double(ab_sw);
    High64ToLow(v4, v3, ab_sw);
    Low64ToHigh(v5, v3, ab_sw);
    assert(v4 == to_quad32(ab_hi)); //OBSERVE
    assert(v5 == to_quad32(ab_lo)); //OBSERVE

    VPolyMul(v3, v3, v2);

    lemma_of_to_quad32(ab_hi);
    lemma_degree_negative(div(ab_hi, n));
    lemma_shift_is_div(ab_hi, 64);
    VPolyMulLow(v4, v4, v2);

    lemma_of_to_quad32(ab_lo);
    lemma_div_mod_exact(div(ab, n), n);
    lemma_mask_is_mod(ab_lo, 64);
    VPolyMulHigh(v5, v5, v2);

    lemma_of_to_quad32(cd);
    lemma_mask_is_mod(ab_sw, 64);
    lemma_shift_is_div(ab_sw, 64);
    lemma_mask_is_mod(cd, 64);
    lemma_shift_is_div(cd, 64);
    assert(of_quad32(v3) == add(ad, bc)); //OBSERVE
    
    lemma_mask_is_mod(ab_hi, 64);
    lemma_mod_mod(ab, n);
    assert(of_quad32(v4) == bd); //OBSERVE

    lemma_shift_is_div(ab_lo, 64);
    assert(of_quad32(v5) == ac); //OBSERVE
    
    Low64ToHigh(v1, v3, add(ad, bc));
    lemma_mod_distribute(ad, bc, n);
    lemma_mul_distribute_left(mod(ad, n), mod(bc, n), n);
    assert(v1 == to_quad32(add(mul(mod(ad, n), n), mul(mod(bc, n), n)))); //OBSERVE
    
    High64ToLow(v2, v3, add(ad, bc));
    lemma_div_distribute(ad, bc, n);
    assert(v2 == to_quad32(add(div(ad, n), div(bc, n)))); //OBSERVE

    AddPoly(v1, v1, v4, add(mul(mod(ad, n), n), mul(mod(bc, n), n)), bd);
    AddPoly(v2, v5, v2, ac, add(div(ad, n), div(bc, n)));

    lemma_add_commute(div(ad, n), div(bc, n));
    lemma_add_associate(ac, div(bc, n), div(ad, n));
    hi := add(add(ac, div(bc, n)), div(ad, n));
    lemma_add_commute(mul(mod(ad, n), n), mul(mod(bc, n), n));
    lo := add(add(mul(mod(bc, n), n), mul(mod(ad, n), n)), bd);

    lemma_gf128_mul(a, b, c, d, 64);
}

procedure ClmulRev128(ghost ab:poly, ghost cd:poly) returns(ghost lo:poly, ghost hi:poly)
    {:quick}
    modifies
        r10;
        v0; v1; v2; v3; v4; v5;
    requires
        degree(ab) <= 127;
        degree(cd) <= 127;
        v1 == to_quad32(reverse(ab, 127));
        v2 == to_quad32(reverse(cd, 127));
    ensures
        degree(lo) <= 127;
        degree(hi) <= 127;
        reverse(mul(ab, cd), 255) == add(shift(hi, 128), lo);
        v1 == to_quad32(lo);
        v2 == to_quad32(hi);
{
    lo, hi := Clmul128(reverse(ab, 127), reverse(cd, 127));
    ShiftLeft2_128_1(lo, hi);

    let m := shift(add(shift(hi, 128), lo), 1);
    lemma_combine_define(hi, lo, 128);
    lemma_split_define(m, 128);
    lo := mod(m, monomial(128));
    hi := div(m, monomial(128));
    lemma_mul_reverse_shift_1(ab, cd, 127);
}

procedure Gf128ModulusRev(inout dst:vec_opr)
    {:quick exportOnly}
    requires @dst != 3;
    modifies
        r10;
        v3;
    ensures
        dst == to_quad32(reverse(gf128_modulus_low_terms, 127));
        of_double32(quad32_double_lo(dst)) == zero;
{
    lemma_gf128_constant_rev(dst);
    Vxor(dst, dst, dst);
    LoadImmShl64(r10, (-7936));
    lemma_ishl_64((-7936) % pow2_64, 16);
    Mtvsrws(v3, r10);
    Vsldoi(dst, v3, dst, 12);
    
    lemma_split_define(reverse(gf128_modulus_low_terms, 127), 64);
    lemma_index_all();
    lemma_reverse_define_all();
    lemma_equal(mod(reverse(gf128_modulus_low_terms, 127), monomial(64)), zero);

    lemma_quad32_double(reverse(gf128_modulus_low_terms, 127));
}

procedure ReduceMulRev128(ghost a:poly, ghost b:poly)
    {:public}
    {:quick}
    modifies
        r10;
        v0; v1; v2; v3; v4; v5; v6;
    requires
        degree(a) <= 127;
        degree(b) <= 127;
        v1 == to_quad32(reverse(a, 127));
        v2 == to_quad32(reverse(b, 127));
    ensures
        v1 == to_quad32(reverse(gf128_mul(a, b), 127));
{
    lemma_gf128_degree();
    lemma_gf128_reduce_rev(a, b, gf128_modulus_low_terms, 128);
    let m := monomial(128);
    let h := gf128_modulus_low_terms;
    let ab := mul(a, b);
    let rh := reverse(h, 127);
    let rab := reverse(ab, 255);
    let rd := mod(rab, m);
    let rdh := reverse(mul(reverse(rd, 127), h), 255);
    let rdhL := mod(rdh, m);
    let rdhLh := reverse(mul(reverse(rdhL, 127), h), 127);

    let (lo1, hi1) := ClmulRev128(a, b);
    lemma_combine_define(hi1, lo1, 128);
    Vmr(v6, v2); // div(rab, m);

    Gf128ModulusRev(v2);
    let (lo2, hi2) := ClmulRev128(reverse(rd, 127), h);
    lemma_combine_define(hi2, lo2, 128);
    Vmr(v5, v2); // div(rdh, m);

    Gf128ModulusRev(v2);

    lemma_quad32_double_hi_rev(rdhL);
    lemma_quad32_double_hi_rev(rh);
    ClmulRev64High(reverse(rdhL, 127), h);

    AddPoly(v1, v1, v5, rdhLh, div(rdh, m));
    AddPoly(v1, v1, v6, add(rdhLh, div(rdh, m)), div(rab, m));
}

procedure Gf128MulRev128()
    {:public}
    {:quick}
    lets
        a := of_quad32(v1);
        b := of_quad32(v2);
    modifies
        r10;
        v0; v1; v2; v3; v4; v5; v6;
    ensures
        of_quad32(v1) == gf128_mul_rev(a, b);
{
    ReduceMulRev128(reverse(a, 127), reverse(b, 127));
    lemma_of_to_quad32(gf128_mul_rev(a, b));
}
