include "Vale.PPC64LE.InsBasic.vaf"
include "Vale.PPC64LE.InsMem.vaf"
include{:fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "Vale.Def.Words_s"
include{:fstar}{:open} "Vale.Def.Words.Two_s"
include{:fstar}{:open} "Vale.Def.Words.Four_s"
include{:fstar}{:open} "Vale.Def.Words.Seq_s"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:fstar}{:open} "Vale.PPC64LE.Machine_s"
include{:fstar}{:open} "Vale.PPC64LE.State"
include{:fstar}{:open} "Vale.PPC64LE.Decls"
include{:fstar}{:open} "Vale.PPC64LE.QuickCode"
include{:fstar}{:open} "Vale.PPC64LE.Memory"
include{:fstar}{:open} "Vale.PPC64LE.Memory_Sems"
include{:fstar}{:open} "Vale.Def.Sel"
include{:fstar}{:open} "Spec.SHA2"
include{:fstar}{:open} "Vale.SHA.PPC64LE.SHA_helpers"
include{:fstar}{:open} "Vale.AES.AES_common_s"
include{:fstar}{:open} "Vale.AES.AES_BE_s"
include{:fstar}{:open} "Vale.Math.Poly2_s"
include{:fstar}{:open} "Vale.Math.Poly2.Bits_s"

module Vale.PPC64LE.InsVector

#verbatim{:interface}
open FStar.Seq
open FStar.Mul
open Vale.Def.Words_s
open Vale.Def.Words.Two_s
open Vale.Def.Words.Four_s
open Vale.Def.Types_s
open Vale.PPC64LE.Machine_s
open Vale.PPC64LE.State
open Vale.PPC64LE.Decls
open Vale.PPC64LE.QuickCode
open Vale.PPC64LE.InsBasic
open Vale.PPC64LE.InsMem
open Vale.PPC64LE.Memory
open Vale.Def.Sel
open Spec.SHA2
open Spec.Hash.Definitions
open Vale.SHA.PPC64LE.SHA_helpers
open Vale.AES.AES_BE_s
open Vale.Math.Poly2_s
open Vale.Math.Poly2.Bits_s

let buffer128_write (b:buffer128) (i:int) (v:quad32) (h:vale_heap) : Ghost vale_heap
  (requires buffer_readable h b /\ buffer_writeable b)
  (ensures fun _ -> True)
  =
  buffer_write b i v h
#endverbatim

#verbatim
open Vale.Def.Types_s
open Vale.PPC64LE.Machine_s
open Vale.PPC64LE.State
open Vale.PPC64LE.Decls
open Spec.Hash.Definitions
open Spec.SHA2
friend Vale.PPC64LE.Decls
module S = Vale.PPC64LE.Semantics_s
#reset-options "--initial_fuel 2 --max_fuel 4 --max_ifuel 2 --z3rlimit 50"
#endverbatim

function buffer128_write(b:buffer128, i:int, v:quad32, h:vale_heap):vale_heap extern;

var v0:quad32 {:state vec(0)};
var v1:quad32 {:state vec(1)};
var v2:quad32 {:state vec(2)};
var v3:quad32 {:state vec(3)};
var v4:quad32 {:state vec(4)};
var v5:quad32 {:state vec(5)};
var v6:quad32 {:state vec(6)};
var v7:quad32 {:state vec(7)};
var v8:quad32 {:state vec(8)};
var v9:quad32 {:state vec(9)};
var v10:quad32 {:state vec(10)};
var v11:quad32 {:state vec(11)};
var v12:quad32 {:state vec(12)};
var v13:quad32 {:state vec(13)};
var v14:quad32 {:state vec(14)};
var v15:quad32 {:state vec(15)};
var v16:quad32 {:state vec(16)};
var v17:quad32 {:state vec(17)};
var v18:quad32 {:state vec(18)};
var v19:quad32 {:state vec(19)};
var v20:quad32 {:state vec(20)};
var v21:quad32 {:state vec(21)};
var v22:quad32 {:state vec(22)};
var v23:quad32 {:state vec(23)};
var v24:quad32 {:state vec(24)};
var v25:quad32 {:state vec(25)};
var v26:quad32 {:state vec(26)};
var v27:quad32 {:state vec(27)};
var v28:quad32 {:state vec(28)};
var v29:quad32 {:state vec(29)};
var v30:quad32 {:state vec(30)};
var v31:quad32 {:state vec(31)};

// Operands of vector registers
operand_type vec_opr:quad32 @ nat8 :=
| inout v0 | inout v1 | inout v2 | inout v3
| inout v4 | inout v5 | inout v6 | inout v7
| inout v8 | inout v9 | inout v10 | inout v11
| inout v12 | inout v13 | inout v14 | inout v15
| inout v16 | inout v17 | inout v18 | inout v19
| inout v20 | inout v21 | inout v22 | inout v23
| inout v24 | inout v25 | inout v26 | inout v27
| inout v28 | inout v29 | inout v30 | inout v31
;

type sim:Type(0) := int_range((-16), 15);

// Move content of vector register to vector register
procedure Vmr(out dst:vec_opr, in src:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vmr(dst, src))}
    ensures
        dst == src;
{
}

// Move high 64-bit of vector register to general-purpose register
procedure Mfvsrd(out dst:reg_opr, in src:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mfvsrd(dst, src))}
    ensures
        dst == hi64(src);
{
    hi64_reveal();
}

// Move low 64-bit of vector register to general-purpose register
procedure Mfvsrld(out dst:reg_opr, in src:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mfvsrld(dst, src))}
    ensures
        dst == lo64(src);
{
    lo64_reveal();
}

// Move joint of two general-purpose registers to vector register
procedure Mtvsrdd(out dst:vec_opr, in src1:reg_opr, in src2:reg_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mtvsrdd(dst, src1, src2))}
    ensures
        pow2_32 * dst.hi3 + dst.hi2 == old(src1);
        pow2_32 * dst.lo1 + dst.lo0 == old(src2);
        dst == old(two_two_to_four(Mktwo(
            Mktwo(src2 % pow2_32, src2 / pow2_32), 
            Mktwo(src1 % pow2_32, src1 / pow2_32))));
{
}

// Move low-order 32-bit of general-purpose register to word elements of vector register
procedure Mtvsrws(out dst:vec_opr, in src:reg_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mtvsrws(dst, src))}
    ensures
        dst.lo0 == old(src) % pow2_32;
        dst.lo1 == old(src) % pow2_32;
        dst.hi2 == old(src) % pow2_32;
        dst.hi3 == old(src) % pow2_32;
{
}

procedure Vadduwm(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vadduwm(dst, src1, src2))}
    ensures
        dst == old(add_wrap_quad32(src1, src2));
{
}

// XOR operation of two vector registers
procedure Vxor(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vxor(dst, src1, src2))}
    ensures
        dst == old(quad32_xor(src1, src2));
{
}

// AND operation of two vector registers
procedure Vand(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vand(dst, src1, src2))}
    ensures
        dst == four_map2(fun(di:nat32, si:nat32) iand32(di, si), old(src1), old(src2));
{
}

// Shift left word elements of vector register with correspinding bit values in word elements of vector register
procedure Vslw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vslw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(
            ishl32(src1.lo0, src2.lo0 % 32),
            ishl32(src1.lo1, src2.lo1 % 32),
            ishl32(src1.hi2, src2.hi2 % 32),
            ishl32(src1.hi3, src2.hi3 % 32)));
{
}

// Shift right word elements of vector register with corresponding bit values in word elements of vector register
procedure Vsrw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsrw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(
            ishr32(src1.lo0, src2.lo0 % 32),
            ishr32(src1.lo1, src2.lo1 % 32),
            ishr32(src1.hi2, src2.hi2 % 32),
            ishr32(src1.hi3, src2.hi3 % 32)));
{
}

// Shift left 128-bit content of vector register with specific bit value
procedure Vsl(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsl(dst, src1, src2))}
    requires
        let sh := index(#(seq(nat8))(nat32_to_be_bytes(src2.lo0)), 3) % 8 in
        let chk := fun (v:nat32, sh:nat8) (let bytes := #(seq(nat8))(nat32_to_be_bytes(v)) in 
            sh = index(bytes, 3) % 8 /\ sh = index(bytes, 2) % 8 /\ sh = index(bytes, 1) % 8 /\ sh = index(bytes, 0) % 8) in
        chk(src2.lo0, sh) /\ chk(src2.lo1, sh) /\ chk(src2.hi2, sh) /\ chk(src2.hi3, sh);
    ensures
        let sh := old(index(#(seq(nat8))(nat32_to_be_bytes(src2.lo0)), 3) % 8) in
        let l := old(four_map(fun (i:nat32) ishl32(i, sh), src1)) in
        let r := old(four_map(fun (i:nat32) ishr32(i, 32 - sh), src1)) in
        dst == quad32_xor(l, Mkfour(0, r.lo0, r.lo1, r.hi2));
{
}

//  Compare equal word elements of vector register and store either ones or zeros in the corresponding elements of destination register
procedure Vcmpequw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vcmpequw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(
            if src1.lo0 = src2.lo0 then 0xFFFFFFFF else 0,
            if src1.lo1 = src2.lo1 then 0xFFFFFFFF else 0,
            if src1.hi2 = src2.hi2 then 0xFFFFFFFF else 0,
            if src1.hi3 = src2.hi3 then 0xFFFFFFFF else 0));
{
}

// Joint of last one word of vector register with first 3 words of vector register
procedure Vsldoi(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr, inline count:quad32bytes)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsldoi(dst, src1, src2, count))}
    requires
        count == 4 || count == 8 || count == 12;
    ensures
        count == 4 ==> dst == old(Mkfour(src2.hi3, src1.lo0, src1.lo1, src1.hi2));
        count == 8 ==> dst == old(Mkfour(src2.hi2, src2.hi3, src1.lo0, src1.lo1));
        count == 12 ==> dst == old(Mkfour(src2.lo1, src2.hi2, src2.hi3, src1.lo0));
{
}

procedure Vmrghw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vmrghw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(src2.lo1, src1.lo1, src2.hi3, src1.hi3));
{
}

procedure Xxmrghd(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Xxmrghd(dst, src1, src2))}
    ensures
        dst == old(Mkfour(src2.hi2, src2.hi3, src1.hi2, src1.hi3));
{
}

procedure Vsel(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr, in sel:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsel(dst, src1, src2, sel))}
    ensures
        dst.lo0 == old(isel32(src2.lo0, src1.lo0, sel.lo0));
        dst.lo1 == old(isel32(src2.lo1, src1.lo1, sel.lo1));
        dst.hi2 == old(isel32(src2.hi2, src1.hi2, sel.hi2));
        dst.hi3 == old(isel32(src2.hi3, src1.hi3, sel.hi3));
{
}

// Vector splat source word element across word elements of destination vector register
procedure Vspltw(out dst:vec_opr, in src:vec_opr, inline uim:nat2)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vspltw(dst, src, uim))}
    ensures
        uim == 0 ==> dst == old(Mkfour(src.hi3, src.hi3, src.hi3, src.hi3));
        uim == 1 ==> dst == old(Mkfour(src.hi2, src.hi2, src.hi2, src.hi2));
        uim == 2 ==> dst == old(Mkfour(src.lo1, src.lo1, src.lo1, src.lo1));
        uim == 3 ==> dst == old(Mkfour(src.lo0, src.lo0, src.lo0, src.lo0));
{
}

// Vector splat signed word immediate across word elements of vector register
procedure Vspltisw(out dst:vec_opr, inline src:sim)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vspltisw(dst, src))}
    ensures
        let src_nat32 := int_to_nat32(src) in
        dst == Mkfour(src_nat32, src_nat32, src_nat32, src_nat32);
{
}

// Vector splat signed byte immediate across word elements of vector register
procedure Vspltisb(out dst:vec_opr, inline src:sim)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vspltisb(dst, src))}
    ensures
        let src_nat8 := int_to_nat8(src) in
        let src_nat32 := be_bytes_to_nat32(four_to_seq_BE(Mkfour(src_nat8, src_nat8, src_nat8, src_nat8))) in
        dst == Mkfour(src_nat32, src_nat32, src_nat32, src_nat32);
{
}

procedure Load128_buffer(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128(dst, base, offset))}
    reads
        memLayout;
    requires
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        dst == buffer128_read(b, index, h);
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Store128_buffer(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128(src, base, offset))}
    reads
        memLayout;
    modifies
        mem;
    requires
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, src, h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(src), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure Load128_word4_buffer(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128Word4(dst, base))}
    reads
        memLayout;
    requires
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base == buffer_addr(b, h) + 16 * index;
    ensures
        let buf := buffer128_read(b, index, h) in
        dst.lo0 == buf.hi3 /\
        dst.lo1 == buf.hi2 /\
        dst.hi2 == buf.lo1 /\
        dst.hi3 == buf.lo0;
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Load128_word4_buffer_index(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128Word4Index(dst, base, offset))}
    reads
        memLayout;
    requires
        @offset != 0;
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        let buf := buffer128_read(b, index, h) in
        dst.lo0 == buf.hi3 /\
        dst.lo1 == buf.hi2 /\
        dst.hi2 == buf.lo1 /\
        dst.hi3 == buf.lo0;
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Store128_word4_buffer(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128Word4(src, base))}
    reads
        memLayout;
    modifies
        mem;
    requires
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, Mkfour(src.hi3, src.hi2, src.lo1, src.lo0), h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(Mkfour(src.hi3, src.hi2, src.lo1, src.lo0)), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure Store128_word4_buffer_index(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128Word4Index(src, base, offset))}
    reads
        memLayout;
    modifies
        mem;
    requires
        @offset != 0;
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, Mkfour(src.hi3, src.hi2, src.lo1, src.lo0), h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(Mkfour(src.hi3, src.hi2, src.lo1, src.lo0)), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure Load128_byte16_buffer(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128Byte16(dst, base))}
    reads
        memLayout;
    requires
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base == buffer_addr(b, h) + 16 * index;
    ensures
        dst == reverse_bytes_quad32(buffer128_read(b, index, h));
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Load128_byte16_buffer_index(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128Byte16Index(dst, base, offset))}
    reads
        memLayout;
    requires
        @offset != 0;
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        dst == reverse_bytes_quad32(buffer128_read(b, index, h));
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Store128_byte16_buffer(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128Byte16(src, base))}
    reads
        memLayout;
    modifies
        mem;
    requires
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, reverse_bytes_quad32(src), h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(reverse_bytes_quad32(src)), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure Store128_byte16_buffer_index(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128Byte16Index(src, base, offset))}
    reads
        memLayout;
    modifies
        mem;
    requires
        @offset != 0;
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, reverse_bytes_quad32(src), h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(reverse_bytes_quad32(src)), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure SHA256_sigma0(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw0(dst, src))}
    {:typecheck false}
    requires
        16 <= t < size_k_w_256;
        src.hi3 == ws_opaque(block, t-15);
    ensures
        dst.hi3 == sigma_0_0_partial(t, block);
{
    lemma_sha256_sigma0(old(src), t, block);
}

procedure SHA256_sigma1(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw1(dst, src))}
    {:typecheck false}
    requires
        16 <= t < size_k_w_256;
        src.hi3 == ws_opaque(block, t-2);
    ensures
        dst.hi3 == sigma_0_1_partial(t, block);
{
    lemma_sha256_sigma1(old(src), t, block);
}

procedure SHA256_Sigma0(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w, ghost hash_orig:hash256)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw2(dst, src))}
    requires
        t < size_k_w_256;
        src.hi3 == word_to_nat32(index(#(seq(Vale.SHA.PPC64LE.SHA_helpers.word))(repeat_range_vale(t, block, hash_orig)), 0));
    ensures
        dst.hi3 == sigma_1_0_partial(t, block, hash_orig);
{
    lemma_sha256_sigma2(old(src), t, block, hash_orig);
}

procedure SHA256_Sigma1(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w, ghost hash_orig:hash256)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw3(dst, src))}
    requires
        t < size_k_w_256;
        src.hi3 == word_to_nat32(index(#(seq(Vale.SHA.PPC64LE.SHA_helpers.word))(repeat_range_vale(t, block, hash_orig)), 4));
    ensures
        dst.hi3 == sigma_1_1_partial(t, block, hash_orig);
{
    lemma_sha256_sigma3(old(src), t, block, hash_orig);
}

procedure Vsbox(out dst:vec_opr, in src:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsbox(dst, src))}
    ensures
        dst == old(Mkfour(
            sub_word(src.lo0),
            sub_word(src.lo1),
            sub_word(src.hi2),
            sub_word(src.hi3)));
{
}

// Rotate left word elements of vector register 24 bits
procedure RotWord(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.RotWord(dst, src1, src2))}
    requires
        src2.lo0 == 8 && src2.lo1 == 8 && src2.hi2 == 8 && src2.hi3 == 8;
    ensures
        dst == old(Mkfour(
            rot_word(src1.lo0),
            rot_word(src1.lo1),
            rot_word(src1.hi2),
            rot_word(src1.hi3)));
{
}

procedure Vcipher(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vcipher(dst, src1, src2))}
    ensures
        dst == old(quad32_xor(mix_columns(shift_rows(sub_bytes(src1))), src2));
{
}

procedure Vcipherlast(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vcipherlast(dst, src1, src2))}
    ensures
        dst == old(quad32_xor(shift_rows(sub_bytes(src1)), src2));
{
}

procedure Vncipher(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vncipher(dst, src1, src2))}
    ensures
        dst == old(inv_mix_columns(quad32_xor(inv_sub_bytes(inv_shift_rows(src1)), src2)));
{
}

procedure Vncipherlast(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vncipherlast(dst, src1, src2))}
    ensures
        dst == old(quad32_xor(inv_sub_bytes(inv_shift_rows(src1)), src2));
{
}

procedure Vpmsumd(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vpmsumd(dst, src1, src2))}
    ensures
        dst == old(to_quad32(add(mul(of_double32(quad32_double_lo(src1)), of_double32(quad32_double_lo(src2))), 
            mul(of_double32(quad32_double_hi(src1)), of_double32(quad32_double_hi(src2))))));
{
}
